{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396975c9",
   "metadata": {},
   "source": [
    "❄️ Frostvakt – Modellutvärdering (fast 70/30-split) – Körs i colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f01d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a89de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Steg 1: Installera paket (Colab)\n",
    "!pip -q install scikit-learn pandas numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Steg 2: Ladda upp SQLite-databas (t.ex. weather_history_forcast.db)\n",
    "from google.colab import files\n",
    "import os, shutil\n",
    "\n",
    "def upload_database():\n",
    "    print(\"Klicka på 'Välj filer' och välj din .db-fil (ex. weather_history_forcast.db)\")\n",
    "    uploaded = files.upload()\n",
    "    os.makedirs('/content/data', exist_ok=True)\n",
    "    db_path = None\n",
    "    for fn in uploaded.keys():\n",
    "        dst = f\"/content/data/{fn}\"\n",
    "        shutil.move(fn, dst)\n",
    "        print(\"Fil uppladdad till:\", dst)\n",
    "        if fn.endswith(\".db\"):\n",
    "            db_path = dst\n",
    "    if db_path is None:\n",
    "        raise RuntimeError(\"Hittade ingen .db-fil. Försök igen.\")\n",
    "    return db_path\n",
    "\n",
    "DB_PATH = upload_database()\n",
    "DB_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Steg 3: Funktioner\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Data\n",
    "def fetch_historical_df(db_path: str) -> pd.DataFrame:\n",
    "    q = \"\"\"\n",
    "    SELECT valid_time, temperature_2m, wind_speed_10m, \n",
    "           relative_humidity_2m, dew_point_2m, cloud_cover, pressure_msl,\n",
    "           strftime('%Y', valid_time) as year,\n",
    "           strftime('%m', valid_time) as month,\n",
    "           strftime('%d', valid_time) as day,\n",
    "           strftime('%H', valid_time) as hour\n",
    "    FROM weather_historical\n",
    "    WHERE temperature_2m IS NOT NULL AND wind_speed_10m IS NOT NULL\n",
    "    ORDER BY valid_time\n",
    "    \"\"\"\n",
    "    con = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql(q, con)\n",
    "    con.close()\n",
    "    df['valid_time'] = pd.to_datetime(df['valid_time'])\n",
    "    for c in ['year','month','day','hour']:\n",
    "        df[c] = df[c].astype(int)\n",
    "    df['actual_frost'] = (df['temperature_2m'] <= 0).astype(int)\n",
    "    return df\n",
    "\n",
    "def prepare_features(df: pd.DataFrame):\n",
    "    X = df.copy()\n",
    "    X['temp_dewpoint_diff'] = X['temperature_2m'] - X['dew_point_2m']\n",
    "    X['hour_sin'] = np.sin(2*np.pi*X['hour']/24)\n",
    "    X['hour_cos'] = np.cos(2*np.pi*X['hour']/24)\n",
    "    X['month_sin'] = np.sin(2*np.pi*X['month']/12)\n",
    "    X['month_cos'] = np.cos(2*np.pi*X['month']/12)\n",
    "    X['temp_rolling_3h'] = X['temperature_2m'].rolling(3, min_periods=1).mean()\n",
    "    X['temp_trend'] = X['temperature_2m'] - X['temperature_2m'].rolling(6, min_periods=1).mean()\n",
    "    features = [\n",
    "        'temperature_2m','wind_speed_10m','relative_humidity_2m','dew_point_2m',\n",
    "        'cloud_cover','pressure_msl','temp_dewpoint_diff','hour_sin','hour_cos',\n",
    "        'month_sin','month_cos','temp_rolling_3h','temp_trend'\n",
    "    ]\n",
    "    X = X[features].fillna(X.mean(numeric_only=True))\n",
    "    y = df['actual_frost'].values\n",
    "    return X, y\n",
    "\n",
    "# ---- Regelalgoritmer ----\n",
    "def rule_original(row):\n",
    "    return row['temperature_2m'] <= 0\n",
    "\n",
    "def rule_daytime_filter(row):\n",
    "    hour = row.get('hour', None)\n",
    "    temp_roll = row.get('temp_rolling_3h', row['temperature_2m'])\n",
    "    if hour is not None and 8 <= hour <= 17 and temp_roll > 0:\n",
    "        return False\n",
    "    return row['temperature_2m'] <= 0\n",
    "\n",
    "def rule_cloud_and_daytime(row):\n",
    "    if rule_daytime_filter(row):\n",
    "        return True\n",
    "    cloud = row.get('cloud_cover', np.nan)\n",
    "    wind = row['wind_speed_10m']\n",
    "    temp_roll = row.get('temp_rolling_3h', row['temperature_2m'])\n",
    "    cloud_factor = 1.5 if pd.notna(cloud) and cloud <= 20 else (1.2 if pd.notna(cloud) and cloud <= 50 else 1.0)\n",
    "    limit = 3.0 if cloud_factor >= 1.4 else (2.0 if cloud_factor >= 1.1 else 1.0)\n",
    "    return (temp_roll <= limit) and (wind < 4)\n",
    "\n",
    "def rule_complete(row):\n",
    "    if rule_cloud_and_daytime(row):\n",
    "        return True\n",
    "    hum = row.get('relative_humidity_2m', np.nan)\n",
    "    temp_roll = row.get('temp_rolling_3h', row['temperature_2m'])\n",
    "    wind = row['wind_speed_10m']\n",
    "    if pd.notna(hum) and temp_roll <= 2 and wind < 3 and hum > 85:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def rule_advanced_rolling(row):\n",
    "    if row['temperature_2m'] <= 0:\n",
    "        return True\n",
    "    trend = row.get('temp_trend', 0)\n",
    "    wind = row['wind_speed_10m']\n",
    "    temp_roll = row.get('temp_rolling_3h', row['temperature_2m'])\n",
    "    return (temp_roll <= 2 and wind < 3 and trend < 0)\n",
    "\n",
    "# Eval helpers\n",
    "def tally_metrics(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "    tp = ((y_true==1) & (y_pred==1)).sum()\n",
    "    fp = ((y_true==0) & (y_pred==1)).sum()\n",
    "    fn = ((y_true==1) & (y_pred==0)).sum()\n",
    "    recall = tp/(tp+fn) if (tp+fn)>0 else 0.0\n",
    "    precision = tp/(tp+fp) if (tp+fp)>0 else 0.0\n",
    "    f1 = 2*(precision*recall)/(precision+recall) if (precision+recall)>0 else 0.0\n",
    "    return dict(recall=recall, precision=precision, f1=f1, missade=int(fn), falska=int(fp))\n",
    "\n",
    "def ascii_table(df: pd.DataFrame) -> str:\n",
    "    df = df.copy()\n",
    "    df['Recall'] = (df['recall']*100).round(1).astype(str) + \"%\"\n",
    "    df['Precision'] = (df['precision']*100).round(1).astype(str) + \"%\"\n",
    "    df['F1'] = df['f1'].round(3).map(lambda x: f\"{x:.3f}\")\n",
    "    df['Missade'] = df['missade'].astype(int)\n",
    "    df['Falska'] = df['falska'].astype(int)\n",
    "    show = df[['Algoritm','Recall','Precision','F1','Missade','Falska']].copy()\n",
    "    widths = [max(len(str(x)) for x in show[c]) for c in show.columns]\n",
    "    widths = [max(w, len(col)) for w,col in zip(widths, show.columns)]\n",
    "    header = \"  \".join(col.ljust(w) for col,w in zip(show.columns, widths))\n",
    "    sep = \"-\"*len(header)\n",
    "    lines = [header, sep]\n",
    "    for _, row in show.iterrows():\n",
    "        line = \"  \".join(str(row[c]).ljust(w) for c,w in zip(show.columns, widths))\n",
    "        lines.append(line)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Fast 70/30-split\n",
    "def frost_stratified_split_fixed(df: pd.DataFrame, random_state=42):\n",
    "    \"\"\"Dela upp frost och icke-frost i ca 70/30 till train/test, oberoende per klass.\"\"\"\n",
    "    df = df.sample(frac=1.0, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    frost = df[df['actual_frost'] == 1]\n",
    "    nonfrost = df[df['actual_frost'] == 0]\n",
    "\n",
    "    # Frost 70/30\n",
    "    n_frost_train = int(round(len(frost) * 0.70))\n",
    "    frost_train = frost.iloc[:n_frost_train]\n",
    "    frost_test  = frost.iloc[n_frost_train:]\n",
    "\n",
    "    # Icke-frost 70/30\n",
    "    n_nf_train = int(round(len(nonfrost) * 0.70))\n",
    "    nonfrost_train = nonfrost.iloc[:n_nf_train]\n",
    "    nonfrost_test  = nonfrost.iloc[n_nf_train:]\n",
    "\n",
    "    df_train = pd.concat([frost_train, nonfrost_train], ignore_index=True)                 .sample(frac=1.0, random_state=random_state)\n",
    "    df_test  = pd.concat([frost_test, nonfrost_test], ignore_index=True)                 .sample(frac=1.0, random_state=random_state+1)\n",
    "    return df_train, df_test\n",
    "\n",
    "# Sample weights\n",
    "def make_sample_weights(y: np.ndarray, frost_weight: float = 3.0):\n",
    "    y = np.asarray(y).astype(int)\n",
    "    return np.where(y==1, frost_weight, 1.0).astype(float)\n",
    "\n",
    "# ML-utvärdering med vikter\n",
    "def evaluate_ml_models(X_train, y_train, X_test, y_test, frost_weight=3.0):\n",
    "    weights = make_sample_weights(y_train, frost_weight=frost_weight)\n",
    "    scaler = StandardScaler()\n",
    "    Xtr = scaler.fit_transform(X_train)\n",
    "    Xte = scaler.transform(X_test)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=None, random_state=42, n_jobs=-1),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    # Logistic Regression – sample_weight\n",
    "    m = models[\"Logistic Regression\"]\n",
    "    m.fit(Xtr, y_train, sample_weight=weights)\n",
    "    pred = m.predict(Xte)\n",
    "    rows.append(dict(Algoritm=\"Logistic Regression\", **tally_metrics(y_test, pred)))\n",
    "\n",
    "    # Random Forest – class_weight\n",
    "    rf = models[\"Random Forest\"]\n",
    "    rf.set_params(class_weight={0:1.0, 1:float(frost_weight)})\n",
    "    rf.fit(X_train.values, y_train)\n",
    "    pred = rf.predict(X_test.values)\n",
    "    rows.append(dict(Algoritm=\"Random Forest\", **tally_metrics(y_test, pred)))\n",
    "\n",
    "    # Gradient Boosting – sample_weight\n",
    "    gb = models[\"Gradient Boosting\"]\n",
    "    gb.fit(X_train.values, y_train, sample_weight=weights)\n",
    "    pred = gb.predict(X_test.values)\n",
    "    rows.append(dict(Algoritm=\"Gradient Boosting\", **tally_metrics(y_test, pred)))\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Regelutvärdering\n",
    "def evaluate_rules(df_test: pd.DataFrame):\n",
    "    df_rules = df_test.copy()\n",
    "    df_rules['hour'] = df_rules['valid_time'].dt.hour\n",
    "    preds = [\n",
    "        (\"Original\", df_rules.apply(rule_original, axis=1)),\n",
    "        (\"+ Dagtidsfilter\", df_rules.apply(rule_daytime_filter, axis=1)),\n",
    "        (\"+ Moln & Dagtid\", df_rules.apply(rule_cloud_and_daytime, axis=1)),\n",
    "        (\"+ Komplett (Recommended)\", df_rules.apply(rule_complete, axis=1)),\n",
    "        (\"+ Advanced (Rullande)\", df_rules.apply(rule_advanced_rolling, axis=1)),\n",
    "    ]\n",
    "    rows = []\n",
    "    for name, p in preds:\n",
    "        rows.append(dict(Algoritm=name, **tally_metrics(df_rules['actual_frost'].values, p.values)))\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59645a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Steg 4: Körning ===\n",
    "FROST_WEIGHT = 3.0  # vikt för frost i träning\n",
    "\n",
    "df_all = fetch_historical_df(DB_PATH)\n",
    "\n",
    "# Fast 70/30-split\n",
    "df_train, df_test = frost_stratified_split_fixed(df_all, random_state=42)\n",
    "\n",
    "# Features för respektive split\n",
    "X_train, y_train = prepare_features(df_train)\n",
    "X_test,  y_test  = prepare_features(df_test)\n",
    "\n",
    "# Utvärdera regler + ML\n",
    "rule_eval = evaluate_rules(df_test)\n",
    "ml_eval = evaluate_ml_models(X_train, y_train, X_test, y_test, frost_weight=FROST_WEIGHT)\n",
    "\n",
    "# Kombinera och sortera\n",
    "all_eval = pd.concat([rule_eval, ml_eval], ignore_index=True).sort_values('f1', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Info om splitten\n",
    "print(\"Antal observationer – Train:\", len(df_train), \"Test:\", len(df_test))\n",
    "print(\"Frost i Train:\", df_train['actual_frost'].sum(), \"Frost i Test:\", df_test['actual_frost'].sum())\n",
    "print(\"Icke-frost i Train:\", (df_train['actual_frost']==0).sum(), \"Icke-frost i Test:\", (df_test['actual_frost']==0).sum())\n",
    "all_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6108b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Steg 5: Skriv ut ASCII-tabellen (sista rader i output) ===\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SLUTTABELL\")\n",
    "print(\"=\"*80)\n",
    "print(ascii_table(all_eval))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
